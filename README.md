# P3: Behavioral Cloning
_Kelly Smith_

_January 5, 2017_

<!-- explains the structure of your network and training approach. While we recommend using English for good practice, writing in any language is acceptable (reviewers will translate). There is no minimum word count so long as there are complete descriptions of the problems and the strategies. See the rubric for more details about the expectations. -->

## Network Architecture
The final network architecture was comprised of:

* Input Layer of 16x32x3 (reduced resolution color images)
* Convolutional layer with a 3x3 kernel with 32 feature-layers with valid padding.
* Max-Pooling with a kernel of 2x2 with valid padding.
* Dropout layer with 50% keep probability.
* Convolutional layer with 3x3 kernel with 32 feature-layers with valid pooling.
* Max-Pooling with a kernel of 2x2 with valid padding
* Fully connected layer of 1536 neurons
* Single output neuron 

I had experimented with this basic architecture by attempting to emulate the NVIDIA architecture.  I tried adding a Batch Normalization layer, but the resulting performance was horrible, so I abandoned that approach.  I attempted adding more fully connected layers at the end of the network to help it recognize higher-order features, but this too crippled performance.  In the end, I was able to achieve success with a relatively simple network architecture, and this helped to keep the number of training parameters down.  This, in turn, helped to accelerate training on my laptop (no GPU available for training).

## Training
### Generating Data
I initially attempted the project with driving data that I generated by driving the track with my keyboard input.  However, I quickly recognized that my frequent tapping of the keyboard arrows would serve as poor training data for a regression problem.  

Consequently, I purchased a USB-connected game controller and used that to generate smoother turns around corners.

Ultimately, I reverted to the Udacity-provided training data due to my suspicions that my training data may be hamstringing my network performance.  I had seen on Slack that other students were having success by using the Udacity data, so I knew it was good enough to train a functional model.

### Augmenting Training Data
Although I ultimately used the Udacity training dataset, it was not sufficient to simply use the center image from the camera.  

Inspired by the NVIDIA model, discussions with my mentor, and discussion on Slack, I augmented my training data by including the images captured by the left and right cameras on the vehicle.  For the labels, I simply added a steering bias as the label.  This steering bias became a hyperparameter in my final training of the model.  The final value (after tweaking) was set to 0.30, which corresponds to 7.5 degrees of steering command bias.  Smaller, less aggressive values tended not to produce driving behavior that was more tolerant of lane marker excursions.  Consequently, I trained the model to be more aggressive in avoiding lane lines.

A feature that I implemented but ultimately did not use was the ability to discard random training examples where the steering angle was 0.  I was concerned that the majority of the training data would have a zero (neutral) steering angle command, and that the model would develop a neutral-steering angle bias.  For this reason, I implemented a feature that would discard random samples from the raw training set in a manner similar to drop-out in the network architecture.  This technique was partially inspired by the NVIDIA approach.  In the end, this technique did not appear to be aiding the training, so I simply set the _keep-probability_ to 1.0 to include all neutral steering examples in the training set.

Although supplementing the training data with left and right training data helped, it was not yet sufficient to yield acceptable driving performance.  Therefore, I supplemented the data further by horizontally flipping the orientation of all images and appending them to the training set (with appropriately reversed steering angle labels).

Once I had augmented the original training set with these additional training examples, the Ã§ar was able to successfully drive around the track without crossing the lane lines. 

### Training
Because this problem was a regression problem and not a classification problem, I used the mean squared error as my loss function.  Additionally, I used the ADAM optimizer in lieu of stochastic gradient descent, due to its generally superior convergence performance.

Initially, I trained the model for 20 epochs with mini-batches of 128 samples per batch.  However, experimentation with the number of epochs revealed that the driving performance was improved by training with fewer epochs.  Consequently, I reduced the number of training epochs from 20 to 5.  

I observed that the training and validation accuracy values were relatively meaningless in predicting driving performance on the road.  The values seemed to be sensitive to the network architecture and the number of training examples used.  

## `drive.py` Modifications
### Pre-processing
The images captured real-time in the _autonomous mode_ of the simulator were at full resolution whereas my model expected reduced resolution images.  To ensure compatibility, the real-time images were scaled down and normalized using the same code from my `preprocess.py` functionality used in building the training data. 


### Throttle Control
I tried to avoid modifying the `drive.py` file as much as possible.  However, I found that adjusting the throttle was a useful strategy to successfully handle corners.  By trial and error, I set a threshold on the the model's steering command that separated *slow* and *fast* throttle settings.  This slowed the vehicle down when large turns were commanded (similar to how a human would drive).  

This was a crude way of modeling the way a human would decelerate upon taking a sharp turn.  A better model would decelerate in anticipation of the turn, but the model for this project did not have that capability to *look-ahead* and predict its future actions. 

Future improvements would have the model also predict the throttle setting as well as the steering command. 

## Commentary
I really enjoyed this challenging project because of the open-ended nature of the problem, and the ability to get rapid feedback by observing the performance

The curves after the bridge became the bane of my existence for a few weeks (over the holidays), and this assignment really emphasized to me the importance of quality and quantity of training data when training deep convolutional neural networks.